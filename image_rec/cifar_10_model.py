# -*- coding: utf-8 -*-
"""CIFAR-10-model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ORno8XI-bWjVFywqm-jPnlo0mpQx4fpI
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

"""<h2>Load and Preprocess the Dataset</h2>


 Load the CIFAR-10 dataset, which is the standard dataset for image classification.
 Normalize the images and convert the labels to one-hot encoded vectors for training.



"""

# Load CIFAR-10 dataset
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()

# Normalize pixel valies to be between 0 and 1
x_train, x_test = x_train / 255.0, x_test / 255.0

# Convert classvectors to binary class matrices (one-hot encoding)
y_train = tf.keras.utils.to_categorical(y_train, 10)
y_test = tf.keras.utils.to_categorical(y_test, 10)

"""<h2> Data Augmentation</h2>
 To improve the model's ability to generalize, we apply data augmentation techniques such as random rotation, width and height shift, horzontal flip, and zoom on the training data.
"""

# data aumentation
datagen = ImageDataGenerator(
    rotation_range = 20,
    width_shift_range = 0.2,
    height_shift_range = 0.2,
    horizontal_flip = True,
    zoom_range = 0.2
)

datagen.fit(x_train)

"""<h2>Build the CNN Model</h2>
 Here, we construct a Convolutional Neural Net using keras. The model includes convolutional layers max pooling layers, dropout layers for regularization, and a fully connected layer for classification.

"""

# Build the CNN model
model = Sequential([
    Conv2D(32, (3, 3), activation="relu", input_shape=(32, 32, 3)),
    MaxPooling2D((2, 2)),
    Dropout(0.25),

    Conv2D(64, (3, 3), activation="relu"),
    MaxPooling2D((2, 2)),
    Dropout(0.25),

    Conv2D(128, (3, 3), activation="relu"),
    Flatten(),
    Dropout(0.5),
    Dense(10, activation="softmax")
])

# Compile Model
model.compile(optimizer="adam", loss="categorical_crossentropy", metrics=["accuracy"])

"""<h2>Train the Model</h2>
 We train the CNN model using the training data. We use the augmented data generator for training and set aside a portion of the training data for validation.
"""

# Train the Model
history = model.fit(datagen.flow(x_train, y_train, batch_size=32),
                    steps_per_epoch=len(x_train) / 32, epochs=10,
                    validation_data=(x_test, y_test))

"""<h2>Evaluate the Model</h2>
 We evaluate the model's performance on test dataset and display teh accuracy and loss during training and validation. We also use a confusion matrix and classififcation report for detailed evaluation.
"""

# plot training & validation accuracy and loss
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title("Model Accuracy")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label="Validation Loss")
plt.title("Model Loss")
plt.legend()
plt.show()

# Confusion Matrix and Classification Report
y_pred = model.predict(x_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

cm = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

print("Classification Report:")
print(classification_report(y_true, y_pred_classes))

# saving the model
model.save("cifar10_cnn_model.h5")
print("Alright!")